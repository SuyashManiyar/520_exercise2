{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5dd8e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.10) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "import shutil\n",
    "import subprocess\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "def generate_coverage_report(\n",
    "    code_file_path: str,\n",
    "    test_cases_list: List[str],\n",
    "    output_path: str\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Generate coverage report for code file with given test cases.\n",
    "    \n",
    "    Args:\n",
    "        code_file_path: Path to Python file to test\n",
    "        test_cases_list: List of test assertions like [\"assert candidate(...) == ...\", ...]\n",
    "        output_path: Directory to save coverage reports\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "        - line_coverage: float (percentage)\n",
    "        - branch_coverage: float or None (percentage)\n",
    "        - tests_passed: int\n",
    "        - tests_failed: int\n",
    "        - uncovered_lines: List[int] - line numbers not covered\n",
    "        - uncovered_branches: List[Tuple[int, int]] - (line_number, branch_id) not covered\n",
    "        - output_dir: str - where reports were saved\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Generating Coverage Report\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(f\"Code file: {code_file_path}\")\n",
    "    print(f\"Test cases: {len(test_cases_list)}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Create temporary directory\n",
    "    temp_dir = tempfile.mkdtemp(prefix='coverage_')\n",
    "    \n",
    "    try:\n",
    "        # Copy code file\n",
    "        code_filename = Path(code_file_path).name\n",
    "        code_module = Path(code_file_path).stem\n",
    "        temp_code = os.path.join(temp_dir, code_filename)\n",
    "        shutil.copy2(code_file_path, temp_code)\n",
    "        \n",
    "        # Get function name\n",
    "        with open(code_file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        func_name = 'candidate'\n",
    "        tree = ast.parse(content)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                if not node.name.startswith('_'):\n",
    "                    func_name = node.name\n",
    "                    break\n",
    "        \n",
    "        # Create test file\n",
    "        test_file = os.path.join(temp_dir, 'test_solution.py')\n",
    "        test_content = f\"\"\"import sys\n",
    "from {code_module} import {func_name}\n",
    "\n",
    "candidate = {func_name}\n",
    "skjkasdkd = {func_name}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        for i, test_case in enumerate(test_cases_list):\n",
    "            test_code = test_case.strip()\n",
    "            if not test_code.startswith('assert'):\n",
    "                test_code = f\"assert {test_code}\"\n",
    "            \n",
    "            test_content += f\"\"\"\n",
    "def test_case_{i}():\n",
    "    {test_code}\n",
    "\"\"\"\n",
    "        \n",
    "        with open(test_file, 'w') as f:\n",
    "            f.write(test_content)\n",
    "        \n",
    "        # Run pytest with coverage\n",
    "        coverage_json = os.path.join(temp_dir, 'coverage.json')\n",
    "        html_dir = os.path.join(temp_dir, 'htmlcov')\n",
    "        \n",
    "        cmd = [\n",
    "            'pytest', test_file,\n",
    "            f'--cov={code_module}',\n",
    "            '--cov-branch',\n",
    "            '--cov-report=term-missing',\n",
    "            f'--cov-report=json:{coverage_json}',\n",
    "            f'--cov-report=html:{html_dir}',\n",
    "            '-v', '--tb=short', '-p', 'no:warnings'\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(\n",
    "            cmd, capture_output=True, text=True, cwd=temp_dir, timeout=30\n",
    "        )\n",
    "        \n",
    "        # Parse results\n",
    "        line_cov = 0.0\n",
    "        branch_cov = None\n",
    "        uncovered_lines = []\n",
    "        uncovered_branches = []\n",
    "        \n",
    "        if os.path.exists(coverage_json):\n",
    "            with open(coverage_json, 'r') as f:\n",
    "                cov_data = json.load(f)\n",
    "            \n",
    "            for file_path, data in cov_data.get('files', {}).items():\n",
    "                if code_filename in file_path:\n",
    "                    summary = data.get('summary', {})\n",
    "                    line_cov = summary.get('percent_covered', 0.0)\n",
    "                    \n",
    "                    if 'num_branches' in summary and summary['num_branches'] > 0:\n",
    "                        covered = summary.get('covered_branches', 0)\n",
    "                        total = summary.get('num_branches', 0)\n",
    "                        if total > 0:\n",
    "                            branch_cov = (covered / total) * 100\n",
    "                    \n",
    "                    uncovered_lines = data.get('missing_lines', [])\n",
    "                    \n",
    "                    # Parse missing branches as list of tuples\n",
    "                    branches = data.get('missing_branches', [])\n",
    "                    for branch in branches:\n",
    "                        if len(branch) >= 2:\n",
    "                            uncovered_branches.append((branch[0], branch[1]))\n",
    "                    break\n",
    "        \n",
    "        # Parse test results\n",
    "        import re\n",
    "        passed_match = re.search(r'(\\d+) passed', result.stdout)\n",
    "        failed_match = re.search(r'(\\d+) failed', result.stdout)\n",
    "        \n",
    "        tests_passed = int(passed_match.group(1)) if passed_match else 0\n",
    "        tests_failed = int(failed_match.group(1)) if failed_match else 0\n",
    "        \n",
    "        if tests_passed == 0 and tests_failed == 0:\n",
    "            tests_passed = len(test_cases_list) if 'passed' in result.stdout.lower() else 0\n",
    "            tests_failed = len(test_cases_list) - tests_passed\n",
    "        \n",
    "        # Save outputs\n",
    "        with open(os.path.join(output_path, 'coverage_report.txt'), 'w') as f:\n",
    "            f.write(result.stdout + \"\\n\\n\" + result.stderr)\n",
    "        \n",
    "        if os.path.exists(coverage_json):\n",
    "            shutil.copy2(coverage_json, os.path.join(output_path, 'coverage.json'))\n",
    "        \n",
    "        if os.path.exists(html_dir):\n",
    "            html_out = os.path.join(output_path, 'htmlcov')\n",
    "            if os.path.exists(html_out):\n",
    "                shutil.rmtree(html_out)\n",
    "            shutil.copytree(html_dir, html_out)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"COVERAGE RESULTS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Tests: {tests_passed}/{len(test_cases_list)} passed\")\n",
    "        print(f\"Line Coverage: {line_cov:.1f}%\")\n",
    "        if branch_cov is not None:\n",
    "            print(f\"Branch Coverage: {branch_cov:.1f}%\")\n",
    "        print(f\"\\nUncovered Lines: {uncovered_lines}\")\n",
    "        print(f\"Uncovered Branches: {uncovered_branches}\")\n",
    "        print(f\"\\nReports saved to: {output_path}/\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'line_coverage': line_cov,\n",
    "            'branch_coverage': branch_cov,\n",
    "            'tests_passed': tests_passed,\n",
    "            'tests_failed': tests_failed,\n",
    "            'total_tests': len(test_cases_list),\n",
    "            'uncovered_lines': uncovered_lines,\n",
    "            'uncovered_branches': uncovered_branches,\n",
    "            'output_dir': output_path\n",
    "        }\n",
    "        \n",
    "    finally:\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82735d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_enhanced_tests_prompt(\n",
    "    code: str,\n",
    "    current_testcases: List[str],\n",
    "    uncovered_lines: List[int],\n",
    "    uncovered_branches: List[Tuple[int, int]]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate prompt for LLM to create tests targeting uncovered lines/branches.\n",
    "    \n",
    "    Args:\n",
    "        code: Source code as string\n",
    "        current_testcases: List of existing test assertions\n",
    "        uncovered_lines: List of line numbers not covered\n",
    "        uncovered_branches: List of (line_number, branch_id) tuples not covered\n",
    "        \n",
    "    Returns:\n",
    "        Prompt string for LLM\n",
    "    \"\"\"\n",
    "    # Add line numbers to code\n",
    "    code_lines = code.split('\\n')\n",
    "    numbered_code = '\\n'.join([f\"{i+1:3d}: {line}\" for i, line in enumerate(code_lines)])\n",
    "    \n",
    "    # Format uncovered branches\n",
    "    branch_info = \"\"\n",
    "    if uncovered_branches:\n",
    "        branch_dict = {}\n",
    "        for line, branch in uncovered_branches:\n",
    "            if line not in branch_dict:\n",
    "                branch_dict[line] = []\n",
    "            branch_dict[line].append(branch)\n",
    "        \n",
    "        branch_info = \"\\n**Uncovered Branches:**\\n\"\n",
    "        for line, branches in sorted(branch_dict.items()):\n",
    "            branch_info += f\"  - Line {line}: branches {branches}\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"You are a test generation expert. Generate NEW test cases to increase code coverage.\n",
    "\n",
    "**Code (with line numbers):**\n",
    "```python\n",
    "{numbered_code}\n",
    "```\n",
    "\n",
    "**Uncovered Lines:** {uncovered_lines}\n",
    "{branch_info}\n",
    "\n",
    "**Existing Tests (DO NOT duplicate):**\n",
    "```python\n",
    "{chr(10).join(current_testcases[:10])}\n",
    "{'...' if len(current_testcases) > 10 else ''}\n",
    "```\n",
    "\n",
    "**Task:**\n",
    "Generate 3-5 NEW test cases that specifically target the uncovered lines {uncovered_lines} and branches listed above.\n",
    "\n",
    "**Requirements:**\n",
    "1. Each test must target SPECIFIC uncovered lines/branches\n",
    "2. Test edge cases: empty inputs, None, boundary values, negative numbers\n",
    "3. Test both True and False paths of conditionals\n",
    "4. Format: \"assert candidate(...) == expected_value\"\n",
    "5. DO NOT duplicate existing tests\n",
    "\n",
    "**Output Format (JSON):**\n",
    "Return ONLY valid JSON in this exact format:\n",
    "{{\n",
    "    \"testcases\": [\n",
    "        \"assert candidate(...) == ...\",\n",
    "        \"assert candidate(...) == ...\",\n",
    "        \"assert candidate(...) == ...\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Generate the JSON now:\"\"\"\n",
    "    \n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tests=['assert candidate([2, 3, 4, 1, 2, 4]) == 1',\n",
    " 'assert candidate([-1, -2, -3]) == -6',\n",
    " 'assert candidate([-1, -2, -3, 2, -10]) == -14',\n",
    " 'assert candidate([-9999999999999999]) == -9999999999999999',\n",
    " 'assert candidate([0, 10, 20, 1000000]) == 0',\n",
    " 'assert candidate([-1, -2, -3, 10, -5]) == -6',\n",
    " 'assert candidate([100, -1, -2, -3, 10, -5]) == -6',\n",
    " 'assert candidate([10, 11, 13, 8, 3, 4]) == 3',\n",
    " 'assert candidate([100, -33, 32, -1, 0, -2]) == -33',\n",
    " 'assert candidate([-10]) == -10',\n",
    " 'assert candidate([7]) == 7',\n",
    " 'assert candidate([1, -1]) == -1',\n",
    " 'assert candidate([]) == 0',\n",
    " 'assert candidate([0]) == 0',\n",
    " 'assert candidate([1]) == 1',\n",
    " 'assert candidate([-1]) == -1',\n",
    " 'assert candidate([2, -1, 2]) == -1']\n",
    "\n",
    "code_file = \"codes_enhanced/gemma_Self_Planning/HumanEval_114.py\"\n",
    "test_cases = combined_tests\n",
    "output_dir = \"Task2/test_coverage_output_better_testcases_114\"\n",
    "    \n",
    "    # Step 1: Generate coverage report\n",
    "result = generate_coverage_report(code_file, test_cases, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82df6aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/suyashmaniyar/Desktop/UMass/Courses/SoftwareEngineering/Assignment_02/HumanEval_Analysis_Final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suyashmaniyar/Library/Python/3.10/lib/python/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43d9fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Generating Coverage Report\n",
      "================================================================================\n",
      "\n",
      "Code file: codes_enhanced/gemma_Self_Planning/HumanEval_114.py\n",
      "Test cases: 12\n",
      "\n",
      "================================================================================\n",
      "COVERAGE RESULTS\n",
      "================================================================================\n",
      "Tests: 12/12 passed\n",
      "Line Coverage: 85.7%\n",
      "Branch Coverage: 75.0%\n",
      "\n",
      "Uncovered Lines: [15]\n",
      "Uncovered Branches: [(14, 15)]\n",
      "\n",
      "Reports saved to: Task2/test_coverage_output/\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERATED PROMPT:\n",
      "================================================================================\n",
      "You are a test generation expert. Generate NEW test cases to increase code coverage.\n",
      "\n",
      "**Code (with line numbers):**\n",
      "```python\n",
      "  1: # The problem asks to find the minimum sum of any non-empty sub-array within a given array of integers.\n",
      "  2: # We can use Kadane's algorithm to solve this problem efficiently. Kadane's algorithm is typically used for finding the maximum sub-array sum,\n",
      "  3: # but we can modify it to find the minimum sub-array sum by tracking the minimum sum so far instead of the maximum sum.\n",
      "  4: # The core idea is to iterate through the array and keep track of the current minimum sum ending at each position and the overall minimum sum encountered so far.\n",
      "  5: \n",
      "  6: def minSubArraySum(nums):\n",
      "  7:     \"\"\"\n",
      "  8:     Given an array of integers nums, find the minimum sum of any non-empty sub-array\n",
      "  9:     of nums.\n",
      " 10:     Example\n",
      " 11:     minSubArraySum([2, 3, 4, 1, 2, 4]) == 1\n",
      " 12:     minSubArraySum([-1, -2, -3]) == -6\n",
      " 13:     \"\"\"\n",
      " 14:     if not nums:\n",
      " 15:         return 0  # Handle empty array case\n",
      " 16: \n",
      " 17:     min_so_far = nums[0]\n",
      " 18:     current_min = nums[0]\n",
      " 19: \n",
      " 20:     for i in range(1, len(nums)):\n",
      " 21:         current_min = min(nums[i], current_min + nums[i])\n",
      " 22:         min_so_far = min(min_so_far, current_min)\n",
      " 23: \n",
      " 24:     return min_so_far\n",
      " 25: \n",
      " 26: # Auto-generated aliases for test compatibility\n",
      " 27: candidate = minSubArraySum\n",
      " 28: \n",
      "```\n",
      "\n",
      "**Uncovered Lines:** [15]\n",
      "\n",
      "**Uncovered Branches:**\n",
      "  - Line 14: branches [15]\n",
      "\n",
      "\n",
      "**Existing Tests (DO NOT duplicate):**\n",
      "```python\n",
      "assert candidate([2, 3, 4, 1, 2, 4]) == 1\n",
      "assert candidate([-1, -2, -3]) == -6\n",
      "assert candidate([-1, -2, -3, 2, -10]) == -14\n",
      "assert candidate([-9999999999999999]) == -9999999999999999\n",
      "assert candidate([0, 10, 20, 1000000]) == 0\n",
      "assert candidate([-1, -2, -3, 10, -5]) == -6\n",
      "assert candidate([100, -1, -2, -3, 10, -5]) == -6\n",
      "assert candidate([10, 11, 13, 8, 3, 4]) == 3\n",
      "assert candidate([100, -33, 32, -1, 0, -2]) == -33\n",
      "assert candidate([-10]) == -10\n",
      "...\n",
      "```\n",
      "\n",
      "**Task:**\n",
      "Generate 3-5 NEW test cases that specifically target the uncovered lines [15] and branches listed above.\n",
      "\n",
      "**Requirements:**\n",
      "1. Each test must target SPECIFIC uncovered lines/branches\n",
      "2. Test edge cases: empty inputs, None, boundary values, negative numbers\n",
      "3. Test both True and False paths of conditionals\n",
      "4. Format: \"assert candidate(...) == expected_value\"\n",
      "5. DO NOT duplicate existing tests\n",
      "\n",
      "**Output Format (JSON):**\n",
      "Return ONLY valid JSON in this exact format:\n",
      "{\n",
      "    \"testcases\": [\n",
      "        \"assert candidate(...) == ...\",\n",
      "        \"assert candidate(...) == ...\",\n",
      "        \"assert candidate(...) == ...\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "Generate the JSON now:\n"
     ]
    }
   ],
   "source": [
    "def extract_testcases_from_llm_response(\n",
    "    llm_response: str,\n",
    "    existing_testcases: List[str]\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract test cases from LLM response and combine with existing tests.\n",
    "    \n",
    "    Args:\n",
    "        llm_response: Raw response from LLM\n",
    "        existing_testcases: Current list of test cases\n",
    "        \n",
    "    Returns:\n",
    "        Combined list of test cases (existing + new unique ones)\n",
    "    \"\"\"\n",
    "    new_testcases = []\n",
    "    \n",
    "    try:\n",
    "        # Try to parse as JSON\n",
    "        # Remove markdown code blocks if present\n",
    "        response = llm_response.strip()\n",
    "        if '```json' in response:\n",
    "            response = response.split('```json')[1].split('```')[0].strip()\n",
    "        elif '```' in response:\n",
    "            response = response.split('```')[1].split('```')[0].strip()\n",
    "        \n",
    "        data = json.loads(response)\n",
    "        new_testcases = data.get('testcases', [])\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback: extract assert statements\n",
    "        lines = llm_response.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('assert candidate('):\n",
    "                # Clean up\n",
    "                line = line.replace('```python', '').replace('```', '').strip()\n",
    "                if line.endswith(','):\n",
    "                    line = line[:-1]\n",
    "                if line.endswith('\"') or line.endswith(\"'\"):\n",
    "                    # Remove quotes if wrapped\n",
    "                    if line.startswith('\"') or line.startswith(\"'\"):\n",
    "                        line = line[1:-1]\n",
    "                new_testcases.append(line)\n",
    "    \n",
    "    # Deduplicate\n",
    "    def normalize(test):\n",
    "        return \"\".join(test.split()).lower()\n",
    "    \n",
    "    existing_normalized = {normalize(t) for t in existing_testcases}\n",
    "    unique_new = []\n",
    "    \n",
    "    for test in new_testcases:\n",
    "        if normalize(test) not in existing_normalized:\n",
    "            unique_new.append(test)\n",
    "            existing_normalized.add(normalize(test))\n",
    "    \n",
    "    # Combine\n",
    "    combined = existing_testcases + unique_new\n",
    "    \n",
    "    print(f\"\\nExtracted {len(new_testcases)} test cases from LLM\")\n",
    "    print(f\"Unique new tests: {len(unique_new)}\")\n",
    "    print(f\"Total tests: {len(combined)}\")\n",
    "    \n",
    "    return combined\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example\n",
    "    code_file = \"codes_enhanced/gemma_Self_Planning/HumanEval_114.py\"\n",
    "    test_cases =  [\n",
    "        \"assert candidate([2, 3, 4, 1, 2, 4]) == 1\",\n",
    "        \"assert candidate([-1, -2, -3]) == -6\",\n",
    "        \"assert candidate([-1, -2, -3, 2, -10]) == -14\",\n",
    "        \"assert candidate([-9999999999999999]) == -9999999999999999\",\n",
    "        \"assert candidate([0, 10, 20, 1000000]) == 0\",\n",
    "        \"assert candidate([-1, -2, -3, 10, -5]) == -6\",\n",
    "        \"assert candidate([100, -1, -2, -3, 10, -5]) == -6\",\n",
    "        \"assert candidate([10, 11, 13, 8, 3, 4]) == 3\",\n",
    "        \"assert candidate([100, -33, 32, -1, 0, -2]) == -33\",\n",
    "        \"assert candidate([-10]) == -10\",\n",
    "        \"assert candidate([7]) == 7\",\n",
    "        \"assert candidate([1, -1]) == -1\"\n",
    "    ]\n",
    "    output_dir = \"Task2/test_coverage_output\"\n",
    "    \n",
    "    # Step 1: Generate coverage report\n",
    "    result = generate_coverage_report(code_file, test_cases, output_dir)\n",
    "    \n",
    "    # Step 2: Read code\n",
    "    with open(code_file, 'r') as f:\n",
    "        code = f.read()\n",
    "    \n",
    "    # Step 3: Generate prompt\n",
    "    prompt = generate_enhanced_tests_prompt(\n",
    "        code,\n",
    "        test_cases,\n",
    "        result['uncovered_lines'],\n",
    "        result['uncovered_branches']\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATED PROMPT:\")\n",
    "    print(\"=\"*80)\n",
    "    print(prompt)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted 5 test cases from LLM\n",
      "Unique new tests: 5\n",
      "Total tests: 17\n",
      "\n",
      "Combined test cases: 17\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=YOUR_API_KEY)\n",
    "MODEL_NAME = \"gemma-3-27b-it\"\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    MODEL_NAME,\n",
    "    generation_config={\n",
    "        \"temperature\": 2,\n",
    "        \"max_output_tokens\": 2048,\n",
    "    },\n",
    ")\n",
    "response = model.generate_content(prompt)\n",
    "llm_response = response.text\n",
    "\n",
    "\n",
    "combined_tests = extract_testcases_from_llm_response(llm_response, test_cases)\n",
    "print(f\"\\nCombined test cases: {len(combined_tests)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94d5857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a test generation expert. Generate NEW test cases to increase code coverage.\n",
      "\n",
      "**Code (with line numbers):**\n",
      "```python\n",
      "  1: # The problem asks to find the minimum sum of any non-empty sub-array within a given array of integers.\n",
      "  2: # We can use Kadane's algorithm to solve this problem efficiently. Kadane's algorithm is typically used for finding the maximum sub-array sum,\n",
      "  3: # but we can modify it to find the minimum sub-array sum by tracking the minimum sum so far instead of the maximum sum.\n",
      "  4: # The core idea is to iterate through the array and keep track of the current minimum sum ending at each position and the overall minimum sum encountered so far.\n",
      "  5: \n",
      "  6: def minSubArraySum(nums):\n",
      "  7:     \"\"\"\n",
      "  8:     Given an array of integers nums, find the minimum sum of any non-empty sub-array\n",
      "  9:     of nums.\n",
      " 10:     Example\n",
      " 11:     minSubArraySum([2, 3, 4, 1, 2, 4]) == 1\n",
      " 12:     minSubArraySum([-1, -2, -3]) == -6\n",
      " 13:     \"\"\"\n",
      " 14:     if not nums:\n",
      " 15:         return 0  # Handle empty array case\n",
      " 16: \n",
      " 17:     min_so_far = nums[0]\n",
      " 18:     current_min = nums[0]\n",
      " 19: \n",
      " 20:     for i in range(1, len(nums)):\n",
      " 21:         current_min = min(nums[i], current_min + nums[i])\n",
      " 22:         min_so_far = min(min_so_far, current_min)\n",
      " 23: \n",
      " 24:     return min_so_far\n",
      " 25: \n",
      " 26: # Auto-generated aliases for test compatibility\n",
      " 27: candidate = minSubArraySum\n",
      " 28: \n",
      "```\n",
      "\n",
      "**Uncovered Lines:** [15]\n",
      "\n",
      "**Uncovered Branches:**\n",
      "  - Line 14: branches [15]\n",
      "\n",
      "\n",
      "**Existing Tests (DO NOT duplicate):**\n",
      "```python\n",
      "assert candidate([2, 3, 4, 1, 2, 4]) == 1\n",
      "assert candidate([-1, -2, -3]) == -6\n",
      "assert candidate([-1, -2, -3, 2, -10]) == -14\n",
      "assert candidate([-9999999999999999]) == -9999999999999999\n",
      "assert candidate([0, 10, 20, 1000000]) == 0\n",
      "assert candidate([-1, -2, -3, 10, -5]) == -6\n",
      "assert candidate([100, -1, -2, -3, 10, -5]) == -6\n",
      "assert candidate([10, 11, 13, 8, 3, 4]) == 3\n",
      "assert candidate([100, -33, 32, -1, 0, -2]) == -33\n",
      "assert candidate([-10]) == -10\n",
      "...\n",
      "```\n",
      "\n",
      "**Task:**\n",
      "Generate 3-5 NEW test cases that specifically target the uncovered lines [15] and branches listed above.\n",
      "\n",
      "**Requirements:**\n",
      "1. Each test must target SPECIFIC uncovered lines/branches\n",
      "2. Test edge cases: empty inputs, None, boundary values, negative numbers\n",
      "3. Test both True and False paths of conditionals\n",
      "4. Format: \"assert candidate(...) == expected_value\"\n",
      "5. DO NOT duplicate existing tests\n",
      "\n",
      "**Output Format (JSON):**\n",
      "Return ONLY valid JSON in this exact format:\n",
      "{\n",
      "    \"testcases\": [\n",
      "        \"assert candidate(...) == ...\",\n",
      "        \"assert candidate(...) == ...\",\n",
      "        \"assert candidate(...) == ...\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "Generate the JSON now:\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97e94766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"testcases\": [\n",
      "        \"assert candidate([]) == 0\",\n",
      "        \"assert candidate([0]) == 0\",\n",
      "        \"assert candidate([1]) == 1\",\n",
      "        \"assert candidate([-1]) == -1\",\n",
      "        \"assert candidate([2, -1, 2]) == -1\"\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e7eba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assert candidate([2, 3, 4, 1, 2, 4]) == 1',\n",
       " 'assert candidate([-1, -2, -3]) == -6',\n",
       " 'assert candidate([-1, -2, -3, 2, -10]) == -14',\n",
       " 'assert candidate([-9999999999999999]) == -9999999999999999',\n",
       " 'assert candidate([0, 10, 20, 1000000]) == 0',\n",
       " 'assert candidate([-1, -2, -3, 10, -5]) == -6',\n",
       " 'assert candidate([100, -1, -2, -3, 10, -5]) == -6',\n",
       " 'assert candidate([10, 11, 13, 8, 3, 4]) == 3',\n",
       " 'assert candidate([100, -33, 32, -1, 0, -2]) == -33',\n",
       " 'assert candidate([-10]) == -10',\n",
       " 'assert candidate([7]) == 7',\n",
       " 'assert candidate([1, -1]) == -1',\n",
       " 'assert candidate([]) == 0',\n",
       " 'assert candidate([0]) == 0',\n",
       " 'assert candidate([1]) == 1',\n",
       " 'assert candidate([-1]) == -1',\n",
       " 'assert candidate([2, -1, 2]) == -1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3a665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Generating Coverage Report\n",
      "================================================================================\n",
      "\n",
      "Code file: codes_enhanced/gemma_Self_Planning/HumanEval_114.py\n",
      "Test cases: 17\n",
      "\n",
      "================================================================================\n",
      "COVERAGE RESULTS\n",
      "================================================================================\n",
      "Tests: 17/17 passed\n",
      "Line Coverage: 100.0%\n",
      "Branch Coverage: 100.0%\n",
      "\n",
      "Uncovered Lines: []\n",
      "Uncovered Branches: []\n",
      "\n",
      "Reports saved to: Task2/test_coverage_output_better_testcases_114/\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_tests=['assert candidate([2, 3, 4, 1, 2, 4]) == 1',\n",
    " 'assert candidate([-1, -2, -3]) == -6',\n",
    " 'assert candidate([-1, -2, -3, 2, -10]) == -14',\n",
    " 'assert candidate([-9999999999999999]) == -9999999999999999',\n",
    " 'assert candidate([0, 10, 20, 1000000]) == 0',\n",
    " 'assert candidate([-1, -2, -3, 10, -5]) == -6',\n",
    " 'assert candidate([100, -1, -2, -3, 10, -5]) == -6',\n",
    " 'assert candidate([10, 11, 13, 8, 3, 4]) == 3',\n",
    " 'assert candidate([100, -33, 32, -1, 0, -2]) == -33',\n",
    " 'assert candidate([-10]) == -10',\n",
    " 'assert candidate([7]) == 7',\n",
    " 'assert candidate([1, -1]) == -1',\n",
    " 'assert candidate([]) == 0',\n",
    " 'assert candidate([0]) == 0',\n",
    " 'assert candidate([1]) == 1',\n",
    " 'assert candidate([-1]) == -1',\n",
    " 'assert candidate([2, -1, 2]) == -1']\n",
    "\n",
    "code_file = \"codes_enhanced/gemma_Self_Planning/HumanEval_114.py\"\n",
    "test_cases = combined_tests\n",
    "output_dir = \"Task2/test_coverage_output_better_testcases_114\"\n",
    "    \n",
    "    # Step 1: Generate coverage report\n",
    "result = generate_coverage_report(code_file, test_cases, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_file = \"codes_enhanced/gemma_Self_Planning/HumanEval_114.py\"\n",
    "test_cases = combined_tests\n",
    "output_dir = \"Task2/test_coverage_output_better_testcases_114\"\n",
    "    \n",
    "    # Step 1: Generate coverage report\n",
    "result = generate_coverage_report(code_file, test_cases, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3349e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Generating Coverage Report\n",
      "================================================================================\n",
      "\n",
      "Code file: /Users/suyashmaniyar/Desktop/UMass/Courses/SoftwareEngineering/Assignment_02/HumanEval_Analysis_Final/Task2/APPS_codes/APPS_4467.py\n",
      "Test cases: 5\n",
      "\n",
      "================================================================================\n",
      "COVERAGE RESULTS\n",
      "================================================================================\n",
      "Tests: 5/5 passed\n",
      "Line Coverage: 85.4%\n",
      "Branch Coverage: 77.8%\n",
      "\n",
      "Uncovered Lines: [21, 37, 44]\n",
      "Uncovered Branches: [(20, 21), (32, 28), (36, 37), (43, 44)]\n",
      "\n",
      "Reports saved to: /Users/suyashmaniyar/Desktop/UMass/Courses/SoftwareEngineering/Assignment_02/HumanEval_Analysis_Final/Task2/APPS_reports/apps_4467/\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code_file = \"/Users/suyashmaniyar/Desktop/UMass/Courses/SoftwareEngineering/Assignment_02/HumanEval_Analysis_Final/Task2/APPS_codes/APPS_4467.py\"\n",
    "test_cases =  [\n",
    "      \"assert candidate('3\\\\n2 0\\\\n3 1\\\\n1 3\\\\n4 2\\\\n0 4\\\\n5 5') == '2'\",\n",
    "      \"assert candidate('3\\\\n0 0\\\\n1 1\\\\n5 2\\\\n2 3\\\\n3 4\\\\n4 5') == '2'\",\n",
    "      \"assert candidate('2\\\\n2 2\\\\n3 3\\\\n0 0\\\\n1 1') == '0'\",\n",
    "      \"assert candidate('5\\\\n0 0\\\\n7 3\\\\n2 2\\\\n4 8\\\\n1 6\\\\n8 5\\\\n6 9\\\\n5 4\\\\n9 1\\\\n3 7') == '5'\",\n",
    "      \"assert candidate('5\\\\n0 0\\\\n1 1\\\\n5 5\\\\n6 6\\\\n7 7\\\\n2 2\\\\n3 3\\\\n4 4\\\\n8 8\\\\n9 9') == '4'\"\n",
    "    ]\n",
    "output_dir = \"/Users/suyashmaniyar/Desktop/UMass/Courses/SoftwareEngineering/Assignment_02/HumanEval_Analysis_Final/Task2/APPS_reports/apps_4467\"\n",
    "    \n",
    "    # Step 1: Generate coverage report\n",
    "result = generate_coverage_report(code_file, test_cases, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244461b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
